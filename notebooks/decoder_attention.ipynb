{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "decoder_attention.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbzIT72KBeTX",
        "colab_type": "code",
        "outputId": "a30d8b4e-d10f-4941-8426-cbc6c0bfcede",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, num_of_features, dim_of_features, hidden_size, vocab_size, embedding_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        \n",
        "        self.num_of_features = num_of_features\n",
        "        self.dim_of_features = dim_of_features\n",
        "        self.hidden_size = hidden_size\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.word_embed = nn.Embedding(self.vocab_size, self.embedding_size)\n",
        "        \n",
        "        # LSTM related variables\n",
        "        self.lstm_cell = nn.LSTMCell(embedding_size+dim_of_features, hidden_size)\n",
        "        self.deep_output = nn.Linear(self.hidden_size, self.vocab_size)\n",
        "        \n",
        "  \n",
        "#   def create_feature_matrix(self):\n",
        "#     feature_matrix = [[0 for i in range(vis_dim)] for j in range(vis_num)]\n",
        "#     return feature_matrix\n",
        "  \n",
        "  \n",
        "  def call_softMax(self, input):\n",
        "    a = nn.Softmax(dim=1)(input).float() \n",
        "    return a\n",
        "      \n",
        "  \n",
        "  # Finds the feature to be focused for the current time step \n",
        "  def build_attention_model(self, input):\n",
        "    batch_size = input.size(0)\n",
        "    input_layer = nn.Linear(self.dim_of_features, self.dim_of_features, bias=False)\n",
        "#     input = torch.randn(batch_size, self.num_of_features, self.dim_of_features)\n",
        "    output = input_layer(input)   \n",
        "#     print(\"output size: \", output.size())\n",
        "#     print(input_layer)    \n",
        "    hidden_layer = nn.Linear(self.dim_of_features, self.dim_of_features, bias=False)\n",
        "    input_h = torch.randn(batch_size, 1, self.dim_of_features)\n",
        "    output_h = hidden_layer(input_h)\n",
        "#     print(\"output_h size: \", output_h.size())\n",
        "#     print(hidden_layer)\n",
        "    concat_input = output + output_h\n",
        "#     print(\"concat_input size = \", concat_input.size())\n",
        "    bias = nn.Parameter(torch.zeros(self.num_of_features)).view(1, -1, 1)\n",
        "    fullconnected_layer = nn.ReLU()(concat_input + bias)\n",
        "#     print(\"bias = \", bias) \n",
        "#     print(\"fullconnected_layer = \", fullconnected_layer.size())\n",
        "    \n",
        "    # Add last layer for final transformation\n",
        "    final_layer = nn.Linear(self.dim_of_features, 1, bias=False)\n",
        "    final_output = final_layer(fullconnected_layer)\n",
        "#     print(\"final_output 1 = \", final_output.size())\n",
        "    final_output = final_output.squeeze(2)\n",
        "#     print(\"final_output 2 = \", final_output.size())\n",
        "    a = self.call_softMax(final_output).unsqueeze(2)\n",
        "#     print(\"a = \", (a).size)\n",
        "    new_in = np.multiply(input.detach(), a.detach())\n",
        "    z = torch.sum(new_in, dim=1)\n",
        "#     print(\"z = \", type(z))\n",
        "\n",
        "    return a, z\n",
        "    \n",
        "    "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output size:  torch.Size([32, 196, 512])\n",
            "Linear(in_features=512, out_features=512, bias=False)\n",
            "output_h size:  torch.Size([32, 1, 512])\n",
            "Linear(in_features=512, out_features=512, bias=False)\n",
            "concat_input size =  torch.Size([32, 196, 512])\n",
            "fullconnected_layer =  torch.Size([32, 196, 512])\n",
            "final_output 1 =  torch.Size([32, 196, 1])\n",
            "final_output 2 =  torch.Size([32, 196])\n",
            "a =  <built-in method size of Tensor object at 0x7f2952bffc60>\n",
            "z =  <class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}